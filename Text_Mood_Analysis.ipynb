{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Modd_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ras0JswfKDqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTuNjLswNjfm",
        "colab_type": "code",
        "outputId": "59a94d21-8347-440f-ed8f-d51dcf512f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#Making all letters lowercase\n",
        "data['text'] = data['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "#removing links\n",
        "data['text'] = data['text'].str.replace('http:(\\S*)','')\n",
        "\n",
        "#Removing Punctuation, Symbols\n",
        "data['text'] = data['text'].str.replace('[^\\w\\s]',' ')\n",
        "\n",
        "#Removing Stop Words using NLTK\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "data['text'] = data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
      ],
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IyMPj_BOYXu",
        "colab_type": "code",
        "outputId": "c2a52c45-8a62-41ea-b03f-731733e72c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('wordnet')\n",
        "\n",
        "#Stemming\n",
        "from textblob import Word\n",
        "data['text'] = data['text'].apply(lambda x: \" \".join([Word(word).stem() for word in x.split()]))"
      ],
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH4r712awebq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code to find the top 5000 rarest words appearing in the data\n",
        "freq = pd.Series(' '.join(data['text']).split()).value_counts()[-5000:]\n",
        "\n",
        "#Removing all those rarely appearing words from the data\n",
        "freq = list(freq.index)\n",
        "data['text'] = data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70q1WwKJOwoY",
        "colab_type": "code",
        "outputId": "02941a6f-d48a-4e2f-f207-5aaa9f5a4bdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import preprocessing\n",
        "lbl_enc = preprocessing.LabelEncoder()\n",
        "y = lbl_enc.fit_transform(data.mood.values)\n",
        "\n",
        "lbl_mood_mapping = dict(zip(lbl_enc.classes_, lbl_enc.transform(lbl_enc.classes_)))\n",
        "print(lbl_mood_mapping)"
      ],
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'anger': 0, 'happiness': 1, 'sadness': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iLdXV2wNa_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting into training and testing data in 90:10 ratio\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(data.text.values, y, test_size=0.1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHBN9LjjNtpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting Count Vectors Parameters\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(analyzer='word',ngram_range=(1,3))\n",
        "count_vect.fit(data['text'])\n",
        "X_train_count =  count_vect.transform(X_train)\n",
        "X_val_count =  count_vect.transform(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZbXzn0RPuin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e46584f4-76b4-4f37-e524-4040c34979fa"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb = MultinomialNB()\n",
        "\n",
        "nb.fit(X_train_count, y_train)\n",
        "y_pred = nb.predict(X_val_count)\n",
        "\n",
        "print('naive bayes count vector accuracy %s' % accuracy_score(y_pred, y_val))"
      ],
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naive bayes count vector accuracy 0.7960308710033076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfUsXIkh1Ad-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0659e96f-0f49-47e1-a89f-562d926fc0e8"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
        "lsvm.fit(X_train_count, y_train)\n",
        "y_pred = lsvm.predict(X_val_count)\n",
        "\n",
        "print('lsvm using count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
      ],
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lsvm using count vectors accuracy 0.8125689084895259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9mweNbk1RtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f73110b-1cbd-4773-abf9-df72070ac4d3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(C=1, solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
        "logreg.fit(X_train_count, y_train)\n",
        "y_pred = logreg.predict(X_val_count)\n",
        "\n",
        "print('log reg count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
      ],
      "execution_count": 436,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log reg count vectors accuracy 0.802646085997795\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}