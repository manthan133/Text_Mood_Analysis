{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ras0JswfKDqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('dataset.csv')\n",
        "\n",
        "data = data.drop(data[data.mood == 'love'].index)\n",
        "data = data.drop(data[data.mood == 'neutral'].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTuNjLswNjfm",
        "colab_type": "code",
        "outputId": "519acce1-fd8c-42bc-ebb8-8a481c150cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#Making all letters lowercase\n",
        "data['text'] = data['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "#Removing Punctuation, Symbols\n",
        "data['text'] = data['text'].str.replace('[^\\w\\s]',' ')\n",
        "\n",
        "#Removing Stop Words using NLTK\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "data['text'] = data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IyMPj_BOYXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1452802a-d95b-45d2-9f8b-48d8527022d1"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "\n",
        "#Lemmatisation\n",
        "from textblob import Word\n",
        "data['text'] = data['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "\n",
        "#Correcting Letter Repetitions\n",
        "import re\n",
        "def de_repeat(text):\n",
        "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
        "    return pattern.sub(r\"\\1\\1\", text)\n",
        "\n",
        "#%%\n",
        "data['text'] = data['text'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70q1WwKJOwoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "249c29f7-04bf-4653-b052-bd964db96479"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "lbl_enc = preprocessing.LabelEncoder()\n",
        "y = lbl_enc.fit_transform(data.mood.values)\n",
        "\n",
        "lbl_mood_mapping = dict(zip(lbl_enc.classes_, lbl_enc.transform(lbl_enc.classes_)))\n",
        "print(lbl_mood_mapping)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'happiness': 0, 'sadness': 1, 'worry': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iLdXV2wNa_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting into training and testing data in 90:10 ratio\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(data.text.values, y, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHBN9LjjNtpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting Count Vectors Parameters\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(analyzer='word',ngram_range=(1,3))\n",
        "count_vect.fit(data['text'])\n",
        "X_train_count =  count_vect.transform(X_train)\n",
        "X_val_count =  count_vect.transform(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZbXzn0RPuin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32e1afa2-f077-4a51-edd3-acb70e7fc299"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb = MultinomialNB()\n",
        "\n",
        "nb.fit(X_train_count, y_train)\n",
        "y_pred = nb.predict(X_val_count)\n",
        "\n",
        "print('naive bayes count vector accuracy %s' % accuracy_score(y_pred, y_val))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naive bayes count vector accuracy 0.5514345696291113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfUsXIkh1Ad-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b310a5f7-c7fe-44c5-fcd0-e4fbefe8de20"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
        "lsvm.fit(X_train_count, y_train)\n",
        "y_pred = lsvm.predict(X_val_count)\n",
        "\n",
        "print('lsvm using count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lsvm using count vectors accuracy 0.5787263820853744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9mweNbk1RtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b87ca93d-591d-41da-acb0-f74f7e66480a"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(C=1, solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
        "logreg.fit(X_train_count, y_train)\n",
        "y_pred = logreg.predict(X_val_count)\n",
        "\n",
        "print('log reg count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log reg count vectors accuracy 0.5780265920223933\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}